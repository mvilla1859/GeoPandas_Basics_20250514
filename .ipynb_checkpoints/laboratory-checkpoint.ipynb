{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geodatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodatasets.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodatasets.data['geoda'][\"nyc_neighborhoods\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodatasets.data[\"geoda\"][\"nyc_neighborhoods\"][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodatasets.get_url(\"geoda\" \"nyc_neighborhoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodatasets.get_path(\"geoda\" \"nyc_neighborhoods\")\n",
    "# geodatasets.get_path(\"ny\" \"bb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoods = gpd.read_file(\"../../geopandas_101_DATA/geodatasets/nycnhood_acs/NYC_Nhood ACS2008_12.shp'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from this notebook comes from the [NYC open data portal](https://opendata.cityofnewyork.us/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Geospatial Data with GeoPandas: Supported Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many file types, same read function ```gpd.read_file()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designated pedestrian zones in NYC\n",
    "shapefile = \"../../geopandas_101_DATA/Forrest/data/Pedestrian Zone Shapefile (Tabular)_20241220/geo_export_a7bb075a-41dc-445f-8244-8430e90a8dde.shp\"\n",
    "shapefile_gdf = gpd.read_file(shapefile)\n",
    "shapefile_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a geodataframe from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'geometry': [str(g) for g in shapefile_gdf['geometry']]}\n",
    "ped_zones = gpd.GeoDataFrame(data,\n",
    "                       geometry=gpd.GeoSeries.from_wkt(data['geometry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ped_zones.info())\n",
    "ped_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_zones.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ped_zones.crs)\n",
    "ped_zones.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shapefile_gdf.crs)\n",
    "ped_zones.set_crs(epsg=4326).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC unofficial neighborhoods\n",
    "geojson_fp = \"https://raw.githubusercontent.com/HodgesWardElliott/custom-nyc-neighborhoods/refs/heads/master/custom-pedia-cities-nyc-Mar2018.geojson\"\n",
    "geojson_gdf = gpd.read_file(geojson_fp)\n",
    "geojson_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a geodataframe from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataframe that only has the geometry\n",
    "data = {\"geometry\": [str(g) for g in geojson_gdf['geometry']]}\n",
    "\n",
    "hoods = gpd.GeoDataFrame(\n",
    "    data,\n",
    "    geometry=gpd.GeoSeries.from_wkt(data['geometry'])\n",
    ")\n",
    "hoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoods.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoods.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add a CRS\n",
    "print(geojson_gdf.crs)\n",
    "hoods.set_crs(epsg=4326).explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoods.set_crs(epsg=4618).explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoods.set_crs(epsg=4939).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World rivers\n",
    "gpkg_fp = \"https://ngageoint.github.io/GeoPackage/examples/rivers.gpkg\"\n",
    "gpkg_gdf = gpd.read_file(gpkg_fp)\n",
    "gpkg_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpkg_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a geodataframe from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"geometry\": [str(g) for g in gpkg_gdf[\"geometry\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = gpd.GeoDataFrame(\n",
    "    data,\n",
    "    geometry=gpd.GeoSeries.from_wkt(data[\"geometry\"])\n",
    ")\n",
    "rivers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpkg_gdf.crs)\n",
    "rivers.set_crs(epsg=3857).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Geo Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgb_fp = \"https://github.com/flatgeobuf/flatgeobuf/raw/refs/heads/master/test/data/UScounties.fgb\"\n",
    "fgb_gdf = gpd.read_file(fgb_fp)\n",
    "fgb_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgb_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a geodataframe from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"geometry\": [str(g) for g in fgb_gdf[\"geometry\"]]}\n",
    "# pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = gpd.GeoDataFrame(\n",
    "    data,\n",
    "    geometry=gpd.GeoSeries.from_wkt(data[\"geometry\"])\n",
    ")\n",
    "counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fgb_gdf.crs)\n",
    "counties.set_crs(epsg=4269).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapely's Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, MultiPoint, LineString, MultiLineString, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point\n",
    "point1 = Point([(2,-9)])\n",
    "\n",
    "point1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiPoint\n",
    "point1 = Point([(0, 0)])\n",
    "point2 = Point([(1, 3)])\n",
    "point3 = Point([(2, -1)])\n",
    "\n",
    "MultiPoint([point1, point2, point3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line\n",
    "line1 = LineString([(0, 0), (1, 1)])\n",
    "line1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiLineString\n",
    "line2 = LineString([(2, 2), (3, -2)])\n",
    "\n",
    "MultiLineString([line1, line2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygon\n",
    "poly1 = Polygon([(-4, 0), (3, 8), (5, 9), (10, 6)])\n",
    "poly1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multipolygon\n",
    "poly2 = Polygon([(11, 0), (15, 7), (18, -3)])\n",
    "\n",
    "MultiPolygon([poly1, poly2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgb_fp = \"https://github.com/flatgeobuf/flatgeobuf/raw/refs/heads/master/test/data/UScounties.fgb\"\n",
    "counties = gpd.read_file(fgb_fp)\n",
    "counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World rivers\n",
    "gpkg_fp = \"https://ngageoint.github.io/GeoPackage/examples/rivers.gpkg\"\n",
    "rivers = gpd.read_file(gpkg_fp)\n",
    "rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties.sjoin(rivers.set_crs(counties.crs, allow_override=True), how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers.sjoin(counties.set_crs(rivers.crs, allow_override=True), how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = gpd.read_file(\"../../geopandas_101_DATA/Forrest/data/nyc/SchoolPoints_APS_2024_08_28 (1)/SchoolPoints_APS_2024_08_28.shp\")\n",
    "subways = gpd.read_file(\"../../geopandas_101_DATA/Forrest/data/nyc/nyc_subway_entrances/nyc_subway_entrances.shp\")\n",
    "bike_paths = gpd.read_file(\"../../geopandas_101_DATA/Forrest/data/nyc/New York City Bike Routes_20241223.geojson\")\n",
    "neighborhoods = gpd.read_file(\"https://raw.githubusercontent.com/HodgesWardElliott/custom-nyc-neighborhoods/refs/heads/master/custom-pedia-cities-nyc-Mar2018.geojson\")\n",
    "parks = gpd.read_file(\"../../geopandas_101_DATA/Forrest/data/nyc/Parks Properties_20241223.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [schools, subways, bike_paths, neighborhoods, parks]\n",
    "\n",
    "for frame in frames:\n",
    "    print(frame.geom_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [schools, subways, bike_paths, neighborhoods, parks]\n",
    "for frame in frames:\n",
    "    print(frame.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg = \"EPSG:3857\"\n",
    "\n",
    "schools = schools.to_crs(epsg)\n",
    "subways = subways.to_crs(epsg)\n",
    "bike_paths = bike_paths.to_crs(epsg)\n",
    "neighborhoods = neighborhoods.to_crs(epsg)\n",
    "parks = parks.to_crs(epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(neighborhoods))\n",
    "print(len(parks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.sjoin(parks, how=\"inner\").explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Common Geometry Properties in GeoPandas\n",
    "\n",
    "Here are some of the most used and useful ones:\n",
    "\n",
    "| Property                          | Description                                                           | Output Type                       |\n",
    "| --------------------------------- | --------------------------------------------------------------------- | --------------------------------- |\n",
    "| `geometry.area`                   | Area of a polygon (0 for points/lines)                                | `float`                           |\n",
    "| `geometry.length`                 | Perimeter of a polygon or length of a line                            | `float`                           |\n",
    "| `geometry.bounds`                 | Bounding box as minx, miny, maxx, maxy                                | `tuple` or `Series`               |\n",
    "| `geometry.centroid`               | Returns the center point of the geometry                              | `Point`                           |\n",
    "| `geometry.envelope`               | Minimum bounding rectangle                                            | `Polygon`                         |\n",
    "| `geometry.convex_hull`            | Smallest convex shape that contains the geometry                      | `Polygon`                         |\n",
    "| `geometry.buffer()`               | Region within a specified distance                                    | `Polygon`                         |\n",
    "| `geometry.exterior`               | Outer boundary of a polygon                                           | `LinearRing`                      |\n",
    "| `geometry.boundary`               | Returns lines representing boundaries                                 | `LineString` or `MultiLineString` |\n",
    "| `geometry.representative_point()` | A point guaranteed to lie within the geometry                         | `Point`                           |\n",
    "| `geometry.is_valid`               | Checks if geometry is valid                                           | `bool`                            |\n",
    "| `geometry.is_empty`               | Checks if geometry is empty                                           | `bool`                            |\n",
    "| `geometry.geom_type`              | Returns the type of the geometry object (e.g. `'Polygon'`, `'Point'`) | `str`                             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.geometry[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.geometry.boundary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.geometry[0].convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.geometry.buffer(100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks.geometry.envelope[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_mapped = parks['boundary'].to_crs('EPSG:4326')\n",
    "parks_mapped.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Spatial Relationship Methods\n",
    "\n",
    "These return boolean values and are used to compare two geometries:\n",
    "\n",
    "| Method                                 | Description                                                         | Output Type |\n",
    "| -------------------------------------- | ------------------------------------------------------------------- | ----------- |\n",
    "| `geometry.contains(other)`             | Returns `True` if geometry contains the other                       | `bool`      |\n",
    "| `geometry.within(other)`               | Returns `True` if geometry is within the other                      | `bool`      |\n",
    "| `geometry.crosses(other)`              | Returns `True` if geometries cross each other                       | `bool`      |\n",
    "| `geometry.intersects(other)`           | Returns `True` if geometries intersect                              | `bool`      |\n",
    "| `geometry.touches(other)`              | Returns `True` if geometries share a boundary but do not overlap    | `bool`      |\n",
    "| `geometry.overlaps(other)`             | Returns `True` if geometries overlap but neither contains the other | `bool`      |\n",
    "| `geometry.equals(other)`               | Returns `True` if geometries are exactly equal                      | `bool`      |\n",
    "| `geometry.disjoint(other)`             | Returns `True` if geometries have no points in common               | `bool`      |\n",
    "| `geometry.distance(other)`             | Returns distance between geometries                                 | `float`     |\n",
    "| `geometry.relate(other)`               | Returns DE-9IM string describing the spatial relationship           | `str`       |\n",
    "| `geometry.intersection(other)`         | Returns shared area or line between geometries                      | `Geometry`  |\n",
    "| `geometry.union(other)`                | Returns combined geometry                                           | `Geometry`  |\n",
    "| `geometry.symmetric_difference(other)` | Returns geometry from parts not shared                              | `Geometry`  |\n",
    "| `geometry.difference(other)`           | Returns geometry excluding area of other                            | `Geometry`  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SQL tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though you can do everything in Python using GeoPandas, there are some really good reasons to combine it with the use of SQL or a tool like DuckDB instead:\n",
    "\n",
    "\n",
    "Efficiency\n",
    "\n",
    "* **DuckDB can be faster** for certain operations ‚Äî particularly **spatial joins and aggregations**.\n",
    "* SQL queries are executed within a **high-performance, in-memory engine** (DuckDB), which can outperform pandas/GeoPandas when handling large datasets.\n",
    "\n",
    "\n",
    "Simplified data prep\n",
    "\n",
    "* SQL can **condense data cleaning and transformation** (e.g., joins, filters, type casting) into **fewer lines** of declarative logic.\n",
    "* For example, filtering by date and doing a spatial intersection can be written as one SQL query instead of multiple pandas/GeoPandas steps.\n",
    "\n",
    "\n",
    "Avoiding memory overload\n",
    "\n",
    "* With GeoPandas, you must **load entire datasets into memory**.\n",
    "* DuckDB allows you to **process data on demand** ‚Äî which can be more scalable, especially with large files (like zipped CSVs or remote Parquet files).\n",
    "\n",
    "\n",
    "Combining diverse file types\n",
    "\n",
    "* SQL (via DuckDB) can read **remote or local files**, such as Parquet, CSV, or even GeoPackages, and **query them together**.\n",
    "* This is harder to do cleanly in pure Python.\n",
    "\n",
    "**In short**: It's not about replacing GeoPandas ‚Äî it‚Äôs about giving you more tools for the job; extending the ecosystem. You might use DuckDB/SQL to gain speed, memory efficiency, and cleaner preprocessing ‚Äî especially for **larger datasets** or **more complex queries**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import duckdb\n",
    "\n",
    "\n",
    "# Define PostGIS connection parameters\n",
    "host = \"your_host\"           # e.g., \"localhost\" or your database IP\n",
    "database = \"your_database\"   # Database name\n",
    "user = \"your_user\"           # Username\n",
    "password = \"your_password\"   # Password\n",
    "port = \"5432\"                # Default PostgreSQL port\n",
    "\n",
    "# SQLAlchemy connection string for PostGIS\n",
    "postgis_connection = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(postgis_connection)\n",
    "\n",
    "# Define SQL query to read spatial data\n",
    "# Replace 'your_table_name' with the actual table containing spatial data\n",
    "query = \"SELECT * FROM your_table_name\"\n",
    "\n",
    "# Load the PostGIS table into a GeoDataFrame\n",
    "postgis_gdf = gpd.read_postgis(query, con=engine, geom_col=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "postgis_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pipenv install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Initialize a DuckDB connection\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.query('INSTALL spatial')\n",
    "con.query('LOAD spatial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying remote CSVs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below queries a series of six CSV files that are containd in a zip file, which is hosted in AWS. Those CSVs contain all the bike rides of the NYC Citi Bike system for the for the month of June 2024. Each CSV has the following columns:\n",
    "\n",
    "*ride_id, rideable_type, started_at, ended_at, start_station_name, start_station_id, end_station_name, end_station_id, start_lat, start_lng, end_lat, end_lng, member_casual*\n",
    "\n",
    "Instead of downloading the whole zip file, unzipping it, etc., we can query the CSVs directly and only download the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DuckDB SQL query\n",
    "# Replace \"your_table\" with the table or query containing lat/lon or WKT geometry\n",
    "duckdb_query = \"\"\"\n",
    "SELECT *, ST_AsText(ST_Point(column09, column08)) as geometry\n",
    "FROM read_csv('https://s3.amazonaws.com/tripdata/202406-citibike-tripdata.zip', ignore_errors=true)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute DuckDB query and convert to a Pandas DataFrame\n",
    "duckdb_df = con.query(duckdb_query).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duckdb_df.shape)\n",
    "duckdb_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_gdf = gpd.GeoDataFrame(\n",
    "    duckdb_df,\n",
    "    geometry=gpd.GeoSeries.from_wkt(duckdb_df[\"geometry\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_gdf.head(1000).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying remote GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbh_query = \"\"\"\n",
    "SELECT *\n",
    "FROM ST_Read('https://raw.githubusercontent.com/HodgesWardElliott/custom-nyc-neighborhoods/refs/heads/master/custom-pedia-cities-nyc-Mar2018.geojson')\n",
    "limit 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_df = con.query(nbh_query).to_df()\n",
    "duckdb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run a simultaneous online query of both the CSVs and the GeoJSON files above.\n",
    "\n",
    "This SQL query is designed to perform a spatial analysis that links bicycle trip data to New York City neighborhoods. It illustrates how to integrate geospatial data with real-world activity data using DuckDB, a high-performance analytical database, and ST\\_\\* spatial functions.\n",
    "\n",
    "The query begins by selecting two data sources: a GeoJSON file containing custom-defined NYC neighborhoods (each with a name and polygon geometry), and a zipped CSV file of Citi Bike trips for June 2024. It then performs a spatial join between these two datasets using the `ST_Intersects` function. This spatial predicate checks whether a bike trip‚Äôs starting point (reconstructed from columns 9 and 8 in the trip data‚Äîlikely longitude and latitude, respectively) falls within the geometry of any NYC neighborhood.\n",
    "\n",
    "From there, it filters the results to keep only those trips that occurred on June 15th, 2024. The query groups the results by neighborhood name and geometry, and counts the number of trips that fall into each neighborhood on that day.\n",
    "\n",
    "Finally, the result is a table where each row corresponds to a neighborhood, and includes:\n",
    "\n",
    "* the number of Citi Bike trips that started within its boundaries on June 15, 2024,\n",
    "* the neighborhood name,\n",
    "* and its geometry in well-known text (WKT) format, ready for mapping or further analysis.\n",
    "\n",
    "This analysis is useful for understanding spatial patterns in bike usage‚Äîsuch as identifying which neighborhoods had the most activity on a given day. It demonstrates how spatial joins, data filtering, and aggregation can combine to produce valuable geographic insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbh_query = \"\"\"\n",
    "SELECT \n",
    "    count(b.column00) as count,           -- Count the number of Citi Bike trips that matched the spatial condition\n",
    "    n.neighborhood,                       -- Select the neighborhood name from the neighborhoods GeoJSON\n",
    "    ST_AsText(n.geom) as geom            -- Convert the neighborhood geometry to Well-Known Text (WKT) format for easy readability/output\n",
    "FROM \n",
    "    ST_Read(\n",
    "        'https://raw.githubusercontent.com/HodgesWardElliott/custom-nyc-neighborhoods/refs/heads/master/custom-pedia-cities-nyc-Mar2018.geojson'\n",
    "    ) n                                  -- Load the NYC neighborhood geometries from a remote GeoJSON file; alias this table as 'n'\n",
    "JOIN \n",
    "    read_csv(\n",
    "        'https://s3.amazonaws.com/tripdata/202406-citibike-tripdata.zip', \n",
    "        ignore_errors=true\n",
    "    ) b                                  -- Load the zipped Citi Bike trip data CSV from AWS S3; alias this table as 'b'\n",
    "ON \n",
    "    ST_Intersects(n.geom, ST_Point(column09, column08)) \n",
    "                                         -- Perform a spatial join: check if the starting point of a bike trip \n",
    "                                         -- (constructed from column09 = longitude, column08 = latitude) intersects the neighborhood geometry\n",
    "WHERE \n",
    "    CAST(column02 AS DATE) = DATE '2024-06-15'\n",
    "                                         -- Filter to include only bike trips that took place on June 15, 2024\n",
    "GROUP BY \n",
    "    n.neighborhood, n.geom               -- Group the results by neighborhood name and geometry\n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbh_df = con.query(nbh_query).to_df()\n",
    "nbh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_gdf = gpd.GeoDataFrame(\n",
    "    nbh_df,\n",
    "    geometry=gpd.GeoSeries.from_wkt(nbh_df[\"geom\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet files with ```gpd.read_parquet()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_parquet('../../geopandas_101_DATA/Forrest/data/es_cn.parquet')\n",
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head(100).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somebody he mentioned took the City Bike zip data and transformed int a parquet file [here](https://source.coop/repositories/zluo43/citibike/description). He suggested it as a good tool to practice how to use the ```gdp.read_parquet()``` function. I think his point is that the files themselves are already the results of queries. Each parquet file file in there is the result of a query, so by downoading them it is equivalent to having alrady run the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
